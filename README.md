# ğŸ§  OpsIQ: Self-Improving Operational Intelligence Agent

> **Hackathon:** Self Improving Agents Hack (Datadog / Lightdash / Airia / Modulate)

A self-improving multi-agent operations intelligence system that monitors real-time business signals, investigates anomalies (revenue leakage, billing exceptions), answers business questions, takes governed action, and improves using feedback + eval traces + memory â€” powered by **real LLM reasoning** (Groq) and **4 sponsor integrations**.

---

## Features

### Module 1: Autonomous Analyst
- Ask natural-language business questions
- Get answers with charts, SQL, confidence scores, and follow-up suggestions
- Supported: revenue analysis, refund trends, underbilling by tier, regional breakdowns

### Module 2: Revenue Leak / Exception Triage
- Autonomous anomaly detection across 5 rule types:
  - Duplicate refunds
  - Underbilling (expected vs billed gap)
  - Tier mismatch (subscription vs invoice)
  - Refund spikes by region
  - Suspicious manual credits
- Ranked cases with impact estimation, evidence, and recommended actions
- **Modulate sentiment analysis** on case evidence (risk scoring per case)

### Module 3: QA Lab / Self-Improvement
- Feedback capture (approve / reject / false positive / useful / not useful)
- **LLM-powered evaluation** â€” Groq analyzes run quality, calibration, and generates improvement suggestions
- **LLM-powered memory** â€” AI reasons about feedback to decide threshold adjustments
- Visible improvement: confidence downgrades, threshold adjustments, impact penalties
- Full LLM reasoning log for observability

### Module 4: Real LLM Reasoning (Groq)
- **Orchestrator** â€” LLM analyzes signals, decides investigation strategy, synthesizes findings
- **Evaluator** â€” LLM assesses run quality and generates calibration advice
- **Memory Agent** â€” LLM reasons about feedback to generate learning updates
- All reasoning traces visible in the UI

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Frontend                      â”‚
â”‚  Mission Control â”‚ Triage â”‚ Analyst â”‚ QA Lab â”‚ Sponsors   â”‚
â”‚  (reasoning traces, sentiment scores, real mode badges)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend                         â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Monitor  â”‚â†’â”‚  Triage    â”‚â†’â”‚  Action    â”‚             â”‚
â”‚  â”‚  Agent   â”‚  â”‚  Agent     â”‚  â”‚  Agent    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚       â”‚           â”‚  â”‚              â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”˜  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Datadog  â”‚ â”‚Anomalyâ”‚  â”‚Modu- â”‚ â”‚  Airia   â”‚          â”‚
â”‚  â”‚ Adapter  â”‚ â”‚+Score â”‚  â”‚late  â”‚ â”‚ Adapter  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚Tools  â”‚  â”‚Senti-â”‚ â”‚(Execute  â”‚          â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ment  â”‚ â”‚ API)     â”‚          â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚Lightdash â”‚  â”‚Evaluator â”‚  â”‚ Memory   â”‚               â”‚
â”‚  â”‚ Adapter  â”‚  â”‚  Agent   â”‚  â”‚  Agent   â”‚               â”‚
â”‚  â”‚(Metrics) â”‚  â”‚ (+ LLM)  â”‚  â”‚ (+ LLM)  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Groq LLM      â”‚  â”‚  Orchestrator       â”‚             â”‚
â”‚  â”‚  (llama-3.3-   â”‚  â”‚  (LLM reasoning     â”‚             â”‚
â”‚  â”‚   70b)         â”‚  â”‚   at every step)     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  DuckDB (analytics)  â”‚  SQLite (state)  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Sponsor Tool Usage

| Sponsor | Tool | Role in OpsIQ | Integration |
|---------|------|---------------|-------------|
| **Datadog** | Monitoring & Alerting | Signal source â€” anomaly alerts and metric threshold events trigger autonomous investigation | `app/adapters/datadog_adapter.py` |
| **Lightdash** | BI Analytics | Semantic metric layer â€” 8 metric definitions power the Analyst module; real API uses `Authorization: ApiKey` header | `app/adapters/lightdash_adapter.py` |
| **Airia** | AI Workflow Orchestration | Action routing â€” cases, alerts, approvals flow through governed Airia pipelines via `POST /execute` with `X-API-Key` | `app/adapters/airia_adapter.py` |
| **Modulate** | Sentiment / Risk Analysis | Sentiment scoring on case evidence text â€” detects fraud language, risk indicators; enriches triage cases | `app/adapters/modulate_adapter.py` |

All adapters support **mock mode** (works without API keys) and **real mode** (plug in credentials in `.env`).
**LLM reasoning (Groq) is always active** when `GROQ_API_KEY` is set â€” this is the core intelligence layer.

---

## Tech Stack

- **Python 3.11+**
- **FastAPI** â€” backend API + agent orchestration
- **Streamlit** â€” frontend demo UI (5 pages)
- **Groq** â€” LLM provider (llama-3.3-70b-versatile, free tier)
- **DuckDB** â€” in-memory analytics engine (loaded from CSV)
- **SQLite** â€” persistence for feedback, evals, memory, traces, cases
- **Plotly** â€” interactive charts
- **Pydantic** â€” data models and validation
- **httpx** â€” async HTTP client for sponsor API calls

---

## Project Structure

```
opsiq/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Settings from .env (Groq, sponsors)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models (incl. sentiment_score)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes_health.py    # GET /health
â”‚   â”‚   â”œâ”€â”€ routes_monitor.py   # POST /monitor/run, GET /monitor/signals
â”‚   â”‚   â”œâ”€â”€ routes_triage.py    # GET /triage/cases, POST /triage/rerun
â”‚   â”‚   â”œâ”€â”€ routes_analyst.py   # POST /analyst/query
â”‚   â”‚   â”œâ”€â”€ routes_feedback.py  # POST /feedback, GET /feedback/improvement
â”‚   â”‚   â”œâ”€â”€ routes_eval.py      # GET /eval, GET /llm/status, GET /llm/reasoning
â”‚   â”‚   â”œâ”€â”€ routes_sentiment.py # POST /sentiment/analyze, GET /sentiment/status
â”‚   â”‚   â””â”€â”€ routes_demo.py      # POST /demo/reset, GET /sponsors/status
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ monitor_agent.py    # Signal ingestion from all sources
â”‚   â”‚   â”œâ”€â”€ triage_agent.py     # Anomaly detection â†’ scoring â†’ sentiment â†’ cases
â”‚   â”‚   â”œâ”€â”€ analyst_agent.py    # Business Q&A orchestration
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py  # LLM-powered run quality scoring
â”‚   â”‚   â”œâ”€â”€ memory_agent.py     # LLM-powered feedback â†’ memory updates
â”‚   â”‚   â””â”€â”€ orchestrator.py     # LLM-powered autonomous pipeline
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ anomaly_tool.py     # 5 rule-based anomaly detectors
â”‚   â”‚   â”œâ”€â”€ scoring_tool.py     # Severity/confidence/impact scoring
â”‚   â”‚   â”œâ”€â”€ sql_tool.py         # Template-based SQL query engine
â”‚   â”‚   â””â”€â”€ chart_tool.py       # Plotly chart builder
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ datadog_adapter.py  # Datadog signal ingestion
â”‚   â”‚   â”œâ”€â”€ lightdash_adapter.py# Lightdash metric layer + API
â”‚   â”‚   â”œâ”€â”€ airia_adapter.py    # Airia Execute API workflows
â”‚   â”‚   â”œâ”€â”€ modulate_adapter.py # Modulate sentiment analysis
â”‚   â”‚   â””â”€â”€ llm_client.py       # Groq/OpenAI LLM client + reasoning log
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ data_service.py     # DuckDB loader
â”‚   â””â”€â”€ storage/
â”‚       â”œâ”€â”€ db.py               # SQLite connection + DDL
â”‚       â”œâ”€â”€ case_store.py       # Triage case persistence
â”‚       â”œâ”€â”€ feedback_store.py   # User feedback
â”‚       â”œâ”€â”€ eval_store.py       # Evaluation scores
â”‚       â”œâ”€â”€ memory_store.py     # Self-improvement state
â”‚       â””â”€â”€ trace_store.py      # Run observability
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ streamlit_app.py        # 5-page Streamlit UI
â”‚   â””â”€â”€ components.py           # Reusable UI components
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ seed_data.py            # CSV generator with seeded anomalies
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ subscriptions.csv
â”‚   â”œâ”€â”€ invoices.csv
â”‚   â”œâ”€â”€ payments.csv
â”‚   â”œâ”€â”€ refunds.csv
â”‚   â”œâ”€â”€ usage_events.csv
â”‚   â””â”€â”€ signal_events.csv
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_schemas.py         # Pydantic model tests
â”‚   â”œâ”€â”€ test_config.py          # Config & API key logic tests
â”‚   â”œâ”€â”€ test_adapters.py        # All sponsor adapter tests
â”‚   â”œâ”€â”€ test_storage.py         # SQLite persistence tests
â”‚   â”œâ”€â”€ test_tools.py           # Anomaly detection & scoring tests
â”‚   â”œâ”€â”€ test_agents.py          # Monitor & triage agent tests
â”‚   â””â”€â”€ test_api.py             # Full API endpoint integration tests
â”œâ”€â”€ storage/                    # SQLite DB created at runtime
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## Setup

### Prerequisites
- Python 3.11+
- pip

### Install

```bash
cd opsiq
pip install -r requirements.txt
```

### Configure API Keys

```bash
cp .env.example .env
```

Edit `.env` with your API keys:

```env
# REQUIRED â€” LLM reasoning (free)
GROQ_API_KEY=your_groq_key          # https://console.groq.com â†’ API Keys

# RECOMMENDED â€” Mode setting
OPSIQ_MODE=real                      # "real" enables all real integrations

# OPTIONAL â€” Sponsor APIs (mock mode works without these)
AIRIA_API_KEY=your_airia_key         # https://app.airia.com â†’ Agent Studio â†’ API Key
MODULATE_API_KEY=your_modulate_key   # https://console.modulate.ai â†’ API Key
LIGHTDASH_API_KEY=your_lightdash_key # https://app.lightdash.cloud â†’ Settings â†’ Tokens
LIGHTDASH_URL=https://app.lightdash.cloud
LIGHTDASH_PROJECT_UUID=your_project_uuid
DATADOG_API_KEY=your_dd_key          # https://app.datadoghq.com â†’ Organization Settings
DATADOG_APP_KEY=your_dd_app_key
```

**Minimum for real mode:** Just `GROQ_API_KEY` â€” all sponsor adapters gracefully fall back to mock when their keys are missing.

### Seed Data (if CSVs are missing)

```bash
python data/seed_data.py
```

---

## Run

### 1. Start Backend

```bash
cd opsiq
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 2. Start Frontend (in a separate terminal)

```bash
cd opsiq
python -m streamlit run frontend/streamlit_app.py --server.port 8501
```

### 3. Run Tests

```bash
python -m pytest tests/ -v
```

### 4. Open Browser

- **Frontend:** http://localhost:8501
- **API Docs:** http://localhost:8000/docs

---

## Demo Flow (3-minute walkthrough)

1. **Mission Control** â€” Click "Run Autonomous Investigation"
   - LLM analyzes signals and decides investigation strategy
   - 6 anomaly cases detected, ranked by impact ($2,478 total)
   - Modulate sentiment analysis scores each case's evidence
   - 3 Airia actions created (case, alert, approval task)
   - **LLM reasoning trace** visible â€” see the AI's thought process

2. **Triage Cases** â€” Review the top case (EMEA refund spike, $1,128 impact)
   - See evidence, recommended action, **sentiment risk score**
   - Mark the duplicate refund case as **False Positive**

3. **QA Lab** â€” See the self-improvement in action
   - **LLM Reasoning tab** â€” full log of all AI reasoning calls
   - Memory updated: LLM decides which thresholds to adjust and by how much
   - Evaluation: LLM analyzes calibration and suggests improvements

4. **Triage Cases** â€” Click "Rerun Triage"
   - Duplicate refund case now shows **medium** confidence (was high)
   - Impact reduced from $150 to $127.50 (15% penalty applied)

5. **Analyst** â€” Ask "Why is revenue down this month?"
   - Get answer with chart, SQL, confidence, follow-ups

6. **Sponsor Tools** â€” Show all 4 integrations with activity logs
   - Datadog, Lightdash, Airia, Modulate â€” each with mode indicator and API format

---

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| GET | `/health` | Health check (mode, tables) |
| POST | `/monitor/run` | Run autonomous investigation |
| GET | `/monitor/signals` | Fetch all signals |
| GET | `/triage/cases` | List all cases (with sentiment scores) |
| POST | `/triage/rerun` | Rerun with updated memory |
| POST | `/analyst/query` | Ask a business question |
| POST | `/feedback` | Submit feedback |
| GET | `/feedback/improvement` | Self-improvement summary |
| GET | `/eval/latest` | Latest evaluation |
| GET | `/llm/status` | LLM provider status |
| GET | `/llm/reasoning` | Full LLM reasoning log |
| POST | `/sentiment/analyze` | Analyze text sentiment (Modulate) |
| GET | `/sentiment/status` | Modulate adapter status |
| GET | `/sentiment/log` | Sentiment analysis audit trail |
| GET | `/memory` | Current memory state |
| GET | `/traces/latest` | Latest trace |
| POST | `/demo/reset` | Reset all demo state |
| GET | `/sponsors/status` | Sponsor tool status |
| GET | `/sponsors/activity` | Sponsor activity logs |

---

## Self-Improvement Loop

```
User Feedback â†’ Memory Agent (LLM) â†’ Memory Store â†’ Triage Agent (rerun)
                      â†“
                Evaluator Agent (LLM) â†’ Eval Store â†’ QA Lab UI
```

**What changes on rerun after feedback:**
- LLM reasons about feedback â†’ decides which thresholds to adjust and by how much
- `false_positive_penalty` increases â†’ confidence downgraded for that anomaly type
- Type-specific thresholds adjust (e.g. duplicate window narrows, underbilling threshold rises)
- Scoring tool applies penalty â†’ lower impact scores
- Evaluator (LLM) recalculates correctness and generates calibration advice

---

## Graceful Degradation

| Component | With API Key | Without API Key |
|-----------|-------------|-----------------|
| **Groq LLM** | Real AI reasoning at every step | Deterministic fallback (rule-based) |
| **Airia** | Real pipeline execution via Execute API | Mock workflow with simulated audit trail |
| **Modulate** | Real ToxMod sentiment analysis | Heuristic keyword-based scoring |
| **Lightdash** | Real API queries (charts, SQL runner) | Mock metric layer from DuckDB |
| **Datadog** | Real Events API signal ingestion | Mock signals from CSV seed data |

The system is **fully functional in mock mode** â€” every feature works without any API keys.
With `GROQ_API_KEY` set, the agents become truly intelligent.

---

## License

MIT â€” Built for Self Improving Agents Hack 2026
